#!/usr/bin/env python
# vim:fileencoding=utf-8
#
# Title:        Substack
# License:      GNU General Public License v3 – https://www.gnu.org/licenses/gpl-3.0.html
# Copyright:    Nathan Cook (nathan.cook@gmail.com)
##
# Written:      2020-12-18
# Updated:      2024-11-04
##

__license__ = 'GNU General Public License v3 – https://www.gnu.org/licenses/gpl-3.0.html'
__copyright__ = 'Nathan Cook – 2020-12-19'
__version__ = 'v0.1.1'
__date__ = '2020-12-19'
__author__ = 'topynate'

import json
import re
from html import escape

from mechanize import Request

from calibre.web.feeds.news import BasicNewsRecipe, classes


def safe_text(s):
    return s or ''


def _chapter_label(section, title):
    section = safe_text(section).strip()
    title = safe_text(title).strip()
    if section and title:
        return section + ' | ' + title
    return title or section or 'Contents'


def _wrap_article(soup):
    body = soup.find('body')
    if not body:
        return None
    wrapper = body.find('div', attrs={'class': 'article'})
    if wrapper:
        return wrapper
    wrapper = soup.new_tag('div', attrs={'class': 'article'})
    for child in list(body.contents):
        wrapper.append(child.extract())
    body.append(wrapper)
    return wrapper


def _insert_chap_marker(soup, wrapper, label):
    if not wrapper:
        return
    marker = soup.new_tag('div', attrs={'class': 'x4-chap-marker'})
    marker.string = 'X4CHAP::' + label
    wrapper.insert(0, marker)


class Substack(BasicNewsRecipe):
    title = 'Substack (X4)'
    __author__ = 'topynate, unkn0wn'
    description = 'Use advanced menu if you want to add your own substack handles.'
    oldest_article = 7
    language = 'en'
    max_articles_per_feed = 100
    needs_subscription = 'optional'
    use_embedded_content = False
    masthead_url = 'https://substack.com/img/substack_wordmark.png'
    cover_url = 'https://substack.com/img/substack.png'
    extra_css = '''
        body { font-family: Bookerly, serif; }
        .captioned-image-container, .image-container, .image-caption {font-size: small;}
        img { display:block; margin:0.6em auto; max-width:75%; max-height:45%; width:auto; height:auto; }
        .article { page-break-after: always; }
        .toc-page { page-break-after: always; }
        .toc-section-title { font-size:80%; font-weight:bold; letter-spacing:0.04em; text-transform:uppercase; color:#404040; margin-top:0.8em; }
        .toc-list { margin:0.2em 0 0.6em 1.2em; padding:0; }
        .toc-list li { margin:0.1em 0; }
        .x4-chap-marker { font-size:1px; line-height:1px; color:#ffffff; margin:0; padding:0; }
    '''
    scale_news_images = (360, 480)
    remove_empty_feeds = True
    remove_attributes = ['style', 'height', 'width']
    no_stylesheets = True

    keep_only_tags = [
        classes('post-title post-subtitle subtitle available-content')
    ]

    remove_tags = [
        dict(name=['svg', 'source']),
        classes('subscribe-widget button-wrapper')
    ]

    recipe_specific_options = {
        'auths': {
            'short': 'enter the @handles you subscribe to:\nseperated by a space',
            'long': '@julianmacfarlane @simplicius76 .... ....',
            'default': '@execsum',
        },
        'days': {
            'short': 'Oldest article to download from this news source. In days ',
            'long': 'For example, 0.5, gives you articles from the past 12 hours',
            'default': str(oldest_article),
        },
        'res': {
            'short': 'For hi-res images, select a resolution from the\nfollowing options: 800, 1000, 1200 or 1500',
            'long': 'This is useful for non e-ink devices, and for a lower file size\nthan the default, use 400 or 300.',
            'default': '600',
        },
        'rev': {
            'short': 'Reverse the order of articles in each feed?',
            'long': 'enter yes',
            'default': 'no',
        },
    }

    def __init__(self, *args, **kwargs):
        BasicNewsRecipe.__init__(self, *args, **kwargs)
        d = self.recipe_specific_options.get('days')
        if d and isinstance(d, str):
            self.oldest_article = float(d)
        r = self.recipe_specific_options.get('rev')
        if r and isinstance(r, str):
            if r.lower().strip() == 'yes':
                self.reverse_article_order = True

    # Every Substack publication has an RSS feed at https://{name}.substack.com/feed.
    # The same URL provides either all posts, or all free posts + previews of paid posts,
    # depending on whether you're logged in.
    # feeds          = [
    #     ('Novum Lumen', 'https://novumlumen.substack.com/feed'),    # gratuitously self-promotional example
    # ]

    def get_browser(self):
        br = BasicNewsRecipe.get_browser(self)
        if self.username is not None and self.password is not None:
            br.open('https://substack.com/account/login?redirect=%2F&email=&with_password=')
            data = json.dumps({'email': self.username, 'password': self.password, 'captcha_response':None})
            req = Request(
                url='https://substack.com/api/v1/email-login',
                headers={
                    'Accept': '*/*',
                    'Content-Type': 'application/json',
                    'Origin': 'https://substack.com',
                    'Referer': 'https://substack.com/account/login?redirect=%2F&email=&with_password=',
                },
                data=data,
                method='POST')
            res = br.open(req)
            if res.getcode() != 200:
                raise ValueError('Login failed, check username and password')
        return br

    def get_feeds(self):
        ans = []
        u = self.recipe_specific_options.get('auths')
        if u and isinstance(u, str):
            for x in u.replace('@', ' ').split():
                ans.append('https://' + x + '.substack.com/feed')
        return ans

    def feeds2index(self, feeds):
        toc_entries = []
        for idx, feed in enumerate(feeds):
            section = safe_text(getattr(feed, 'title', '')).strip()
            articles = getattr(feed, 'articles', [])
            titles = []
            for article in articles:
                title = safe_text(getattr(article, 'title', '')).strip()
                if title:
                    titles.append(title)
            toc_entries.append((idx, section or 'Substack', titles))
        return self._render_toc_html(toc_entries)

    def _render_toc_html(self, sections):
        css = (getattr(self, 'template_css', '') or '') + '\n' + (self.get_extra_css() or '')
        parts = [
            '<html><head><title>Contents</title>',
            '<style type="text/css">' + css + '</style>',
            '</head>',
            '<body class="toc-page"><h1>Contents</h1>',
            '<div class="x4-chap-marker">X4CHAP::Contents</div>',
        ]
        for feed_idx, section, titles in sections:
            sec = escape(safe_text(section).strip())
            if not sec:
                continue
            parts.append('<div class="toc-section" id="feed_' + str(feed_idx) + '">')
            parts.append('<div class="toc-section-title">' + sec + '</div>')
            if titles:
                parts.append('<ul class="toc-list">')
                for title in titles:
                    parts.append('<li>' + escape(title) + '</li>')
                parts.append('</ul>')
            parts.append('</div>')
        parts.append('</body></html>')
        return ''.join(parts).encode('utf-8')

    def preprocess_html(self, soup):
        res = '600'
        w = self.recipe_specific_options.get('res')
        if w and isinstance(w, str):
            res = w
        for img in soup.findAll('img', attrs={'src': True}):
            img['src'] = re.sub(r'w_\d+', 'w_' + res, img['src'])
        return soup

    def postprocess_html(self, soup, first_fetch):
        for link in soup.findAll('a', attrs={'rel': 'calibre-downloaded-from'}):
            parent = link.find_parent('p')
            if parent:
                parent.decompose()
            else:
                link.decompose()

        for link in list(soup.findAll('a')):
            if link.get('rel') == 'calibre-downloaded-from':
                continue
            if link.contents:
                link.unwrap()
            else:
                link.decompose()
        return soup

    def internal_postprocess_book(self, oeb, opts, log):
        super(Substack, self).internal_postprocess_book(oeb, opts, log)
        for item in oeb.spine:
            try:
                nodes = item.data.xpath('//*[local-name()="p"][descendant::*[@rel="calibre-downloaded-from"]]')
            except Exception:
                continue
            for p in nodes:
                parent = p.getparent()
                if parent is not None:
                    parent.remove(p)
        for item in oeb.spine:
            try:
                navs = item.data.xpath(
                    '//*[local-name()="div"][contains(concat(" ", normalize-space(@class), " "), " calibre_navbar")]'
                )
            except Exception:
                continue
            for div in navs:
                parent = div.getparent()
                if parent is not None:
                    parent.remove(div)

    def populate_article_metadata(self, article, soup, first):
        wrapper = _wrap_article(soup)
        h1 = soup.find('h1')
        title = ''
        if h1:
            title = self.tag_to_string(h1).strip()
        if not title:
            title = safe_text(getattr(article, 'title', '')).strip()
        label = _chapter_label('', title)
        _insert_chap_marker(soup, wrapper, label)
